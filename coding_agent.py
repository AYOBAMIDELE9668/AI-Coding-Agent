# -*- coding: utf-8 -*-
"""coding agent

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/198RKY_Ia7U05ClphD-yDb5FqzxHqXmmO
"""

!pip install langgraph

!pip install langgraph
import google.generativeai as genai
from langgraph.graph import StateGraph
from pydantic import BaseModel
from typing import Optional

import os
genai.configure(api_key=os.getenv("AIzaSyBf0SMEUfN6haVOS3oSIPQpfi6Su58wlnY"))

"""AGENT STATE"""

class CodingState(BaseModel):
    user_request: str
    explanation: Optional[str] = ""
    code_output: Optional[str] = ""
    improvement: Optional[str] = ""
    debug_result: Optional[str] = ""

"""GEMINI WRAPPER"""

def ask_model(prompt, model_name="gemini-pro"):
    model = genai.GenerativeModel(model_name)
    response = model.generate_content(prompt)
    return response.text

""" NODES"""

# 1. Understand and explain
def explain_node(state: CodingState):
    explanation = ask_model(f"""
    You are a friendly senior developer.
    Explain this request clearly and simply:

    {state.user_request}
    """)
    state.explanation = explanation
    return state

# 2. Generate code
def generate_code_node(state: CodingState):
    code = ask_model(f"""
    Write code for this (no executing):

    {state.user_request}

    Output ONLY code — no extra text.
    """)
    state.code_output = code
    return state

# 3. Improve / Refactor
def improve_node(state: CodingState):
    improvement = ask_model(f"""
    Improve this code with comments, structure, and cleaner logic:

    {state.code_output}
    """)
    state.improvement = improvement
    return state

# 4. Debug (safe — static analysis only)
def debug_node(state: CodingState):
    debug_response = ask_model(f"""
    Review this code for mistakes (do NOT execute it):

    {state.code_output}

    Return:
    - Mistakes
    - Fixes
    - Safer version
    """)
    state.debug_result = debug_response
    return state

"""BUILD GRAPH"""

workflow = StateGraph(CodingState)

workflow.add_node("explain", explain_node)
workflow.add_node("generate_code", generate_code_node)
workflow.add_node("improve", improve_node)
workflow.add_node("debug", debug_node)

workflow.set_entry_point("explain")

workflow.add_edge("explain", "generate_code")
workflow.add_edge("generate_code", "improve")
workflow.add_edge("improve", "debug")

coding_agent = workflow.compile()

"""RUN FUNCTION"""

def run_coding_agent(request: str):
    state = CodingState(user_request=request)
    result = coding_agent.invoke(state)
    return result

import os
import google.generativeai as genai

os.environ["GEMINI_API_KEY"] = "AIzaSyBf0SMEUfN6haVOS3oSIPQpfi6Su58wlnY"

genai.configure(api_key=os.environ["GEMINI_API_KEY"])

# Commented out IPython magic to ensure Python compatibility.
# %%writefile main.py
# import google.generativeai as genai
# from langgraph.graph import StateGraph
# from pydantic import BaseModel
# from typing import Optional
# import os
# 
# # Configure API
# genai.configure(api_key=os.environ["GEMINI_API_KEY"])
# 
# class CodingState(BaseModel):
#     user_request: str
#     explanation: Optional[str] = ""
#     code_output: Optional[str] = ""
#     improvement: Optional[str] = ""
#     debug_result: Optional[str] = ""
# 
# def ask_model(prompt, model="gemini-2.5-flash"):
#     result = genai.generate_text(model=model, prompt=prompt)
#     return result.text
# 
# def explain_node(state: CodingState):
#     state.explanation = ask_model(f"Explain this:\n{state.user_request}")
#     return state
# 
# def generate_code_node(state: CodingState):
#     state.code_output = ask_model(
#         f"Write code for this. Output ONLY code:\n{state.user_request}"
#     )
#     return state
# 
# def improve_node(state: CodingState):
#     state.improvement = ask_model(
#         f"Improve this code:\n{state.code_output}"
#     )
#     return state
# 
# def debug_node(state: CodingState):
#     state.debug_result = ask_model(
#         f"Debug this code safely. Do NOT execute it:\n{state.code_output}"
#     )
#     return state
# 
# workflow = StateGraph(CodingState)
# 
# workflow.add_node("explain", explain_node)
# workflow.add_node("generate_code", generate_code_node)
# workflow.add_node("improve", improve_node)
# workflow.add_node("debug", debug_node)
# 
# workflow.set_entry_point("explain")
# workflow.add_edge("explain", "generate_code")
# workflow.add_edge("generate_code", "improve")
# workflow.add_edge("improve", "debug")
# 
# coding_agent = workflow.compile()
# 
# def run_coding_agent(request: str):
#     state = CodingState(user_request=request)
#     return coding_agent.invoke(state)
#

import os
os.environ["GEMINI_API_KEY"] = "AIzaSyBf0SMEUfN6haVOS3oSIPQpfi6Su58wlnY"

# main.py
import os
import google.generativeai as genai

# -----------------------------------------------------
# 1. Configure Gemini safely
# -----------------------------------------------------

API_KEY = os.environ.get("GEMINI_API_KEY")

if not API_KEY:
    raise ValueError("ERROR: GEMINI_API_KEY environment variable not set.")

genai.configure(api_key=API_KEY)

# -----------------------------------------------------
# 2. Ask Gemini Model
# -----------------------------------------------------
def ask_model(prompt, model="gemini-2.5-flash"):
    """
    Sends a text prompt to Gemini and returns the response.
    """
    response = genai.GenerativeModel(model).generate_content(prompt)
    return response.text


# -----------------------------------------------------
# 3. Coding Agent Logic
# -----------------------------------------------------
def run_coding_agent(request):
    """
    Takes a user request and produces:
      - Explanation
      - Code snippet
      - Optional improvements
    """

    system_prompt = f"""
You are a coding assistant.
Break your answer into:

1. Explanation
2. Working code
3. Improvements

User request: {request}
"""

    result = ask_model(system_prompt)
    return result

import os
os.environ["GEMINI_API_KEY"] = "AIzaSyBf0SMEUfN6haVOS3oSIPQpfi6Su58wlnY"

# Commented out IPython magic to ensure Python compatibility.
# %%writefile main.py
# import os
# import google.generativeai as genai
# 
# # -----------------------------------------------------
# # 1. Configure Gemini safely
# # -----------------------------------------------------
# API_KEY = os.environ.get("GEMINI_API_KEY")
# 
# if not API_KEY:
#     raise ValueError("ERROR: GEMINI_API_KEY environment variable not set.")
# 
# genai.configure(api_key=API_KEY)
# 
# # -----------------------------------------------------
# # 2. Ask Gemini Model
# # -----------------------------------------------------
# def ask_model(prompt, model="gemini-2.5-flash"):
#     model_obj = genai.GenerativeModel(model)
#     result = model_obj.generate_content(prompt)
#     return result.text
# 
# # -----------------------------------------------------
# # 3. Coding Agent Logic
# # -----------------------------------------------------
# def run_coding_agent(request):
#     system_prompt = f"""
# You are a coding assistant.
# Provide:
# 1. Explanation
# 2. Code
# 3. Improvements
# 
# User request: {request}
# """
#     return ask_model(system_prompt)
#

from main import run_coding_agent

result = run_coding_agent("Explain and write Python code for bubble sort.")
print(result)

import pickle
from main import run_coding_agent

# Save the agent (pickle the function or workflow)
with open("coding_agent.pkl", "wb") as f:
    pickle.dump(run_coding_agent, f)

print("Agent saved as coding_agent.pkl")